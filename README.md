# PW_warsztaty_badawcze

## Rozkład zajęć 
- 2025-02-25 - Prezentacja tematyki projektów
- 2025-03-04 - Zajęcie organizacyjne + wprowadzenie do LLM-ów 
- 2025-03-11 - Wrowadzenie teoretyczne do psychologii osobowości + omówienie artykułów 
- 2025-03-18 - Omówienie i dyskusja literatury - grupa 1,2,3 
- 2025-03-25 - Omówienie i dyskusja literatury - grupa 4,5
- 2025-04-01 - Dyskusja projektów 
- 2025-04-08 - Konsultacje projektów indywidualnych (on-line)
- 2025-04-15 - Konsultacje projektów indywidualnych (on-line)
- 2025-04-29 - Konsultacje projektów indywidualnych (on-line) -> Kamień milowy nr 1 
- 2025-05-06 - Przedstawienie postępów projektów 
- 2025-05-20 - Konsultacje projektów indywidualnych -> Kamień milowy nr 2 
- 2025-05-27 - Konsultacje projektów indywidualnych
- 2025-06-03 - Konsultacje projektów indywidualnych
- 2025-06-10 - Przedstawienie finalnych projektów

## Narzędzia
a) Promptowanie 
- https://www.together.ai/ 
- https://ollama.com/
- https://cloud.google.com/model-garden?hl=en 

## Tematy zaliczenia

a) Podstawowe 
b) Zaawansowane

## Dodatkowa punktacja
- Punkty za prace domowe: 1) Techniczną z LLM-ów 2) Psychologia w LLM-ach.
- Aktywność
- Osiągnięcie kamnieni milowych

## Ciekawe githuby
-https://github.com/kasperjunge/LLM-Guide 

## Artykuły
-Zou, H., Wang, P., Yan, Z., Sun, T., & Xiao, Z. (2024). Can LLM" Self-report"?: Evaluating the Validity of Self-report Scales in Measuring Personality Design in LLM-based Chatbots. https://arxiv.org/abs/2412.00207 (edited)
Artykuł ten dotyczy badania, w jaki sposób można ocenić osobowość chatbotów z perspektywy człowieka, rekrutując uczestników do interakcji z chatbotami i wypełniania kwestionariuszy oceny osobowości oraz kwestionariuszy doświadczeń użytkownika.

-Frisch, I., & Giulianelli, M. (2024). LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models. https://arxiv.org/abs/2402.02896 Artykuł analizuje użycie języka w kontekście interakcji agentów LLM, mierząc spójnośćich osobowości. Bada, jak cechy osobowości wpływają na użycie języka w warunkach interaktywnych i nieinteraktywnych, wykorzystując do analiz kategorie LIWC (Linguistic Inquiry and Word Count).

-Gupta, A., Song, X., & Anumanchipalli, G. (2024, November). Self-assessment tests are unreliable measures of llm personality. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP (pp. 301-314). https://aclanthology.org/2024.blackboxnlp-1.20/
Artykuł ten podważa wiarygodność testów samooceny w pomiarze osobowości LLM. Wykazuje, że wyniki testów w LLM nie są odporne na równoważne pytania i kolejność prezentowanych opcji. Badanie to analizuje wrażliwość na sformułowania pytań, porównując odpowiedzi modeli na trzy semantycznie równoważne pytania.

-Mieleszczenko-Kowszewicz, W., Płudowski, D., Kołodziejczyk, F., Świstak, J., Sienkiewicz, J., & Biecek, P. (2024). The Dark Patterns of Personalized Persuasion in Large Language Models: Exposing Persuasive Linguistic Features for Big Five Personality Traits in LLMs Responses. https://arxiv.org/abs/2411.06008

Artykuł bada, w jaki sposób LLM dostosowują swoje odpowiedzi w oparciu o osobowość użytkownika w zadaniu perswazji. Analizuje wzorce językowe używane przez modele w zależności od cech osobowości odbiorcy. W eksperymencie użyto różnorodnego zestawu 19 LLM i analizowano, jak modele te reagują na zmienne w zapytaniach perswazyjnych.

-Zhang, J., Liu, D., Qian, C., Gan, Z., Liu, Y., Qiao, Y., & Shao, J. (2024). The better angels of machine personality: How personality relates to llm safety. https://arxiv.org/abs/2407.12344

Artykuł analizuje, jak można kontrolować i edytować cechy osobowości w LLM, używając techniki wektorów sterujących. Bada, jak różne ustawienia, takie jak język i kolejność opcji, wpływają na ocenę MBTI (Myers-Briggs Type Indicator) dla LLM. W badaniu wykorzystano chińskie i angielskie wersje kwestionariusza MBTI-M, aby ocenić wyniki osobowości LLM w różnych kontekstach kulturowych.

-Petrov, N. B., Serapio-García, G., & Rentfrow, J. (2024). Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis. https://arxiv.org/abs/2405.07248

Artykuł ten bada, czy duże modele językowe (LLM) są w stanie symulować ludzkie zachowania i osobowości. Wykorzystuje rygorystyczne metodologie psychometryczne do oceny, czy LLM mogą naśladować latentne konstrukty psychologiczne, które wpływają na zachowania w różnych zadaniach. Badacze użyli szablonu do zapytań, który zawierał instrukcję dotyczącą osobowości, opis persony, instrukcję testową, treść pytań.


